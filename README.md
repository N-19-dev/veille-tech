# ğŸ§  Veille Tech â€” Data, BI, Cloud & AI

Automatise ta **veille technologique** avec Python :
- ğŸ“° **Crawl** des blogs officiels, articles techniques et sources data/BI/ML.
- ğŸ¤– **Analyse IA** (via **Groq** / Llama 3.1) pour trier les contenus utiles.
- ğŸ§¾ **Exports** JSON & Markdown.
- ğŸ—ï¸ **RÃ©sumÃ© hebdomadaire IA** clair et synthÃ©tique avec liens Ã  creuser.

---

## ğŸš€ FonctionnalitÃ©s

| Ã‰tape | Description |
|--------|--------------|
| **Crawl** | RÃ©cupÃ¨re automatiquement les articles rÃ©cents des blogs techniques (RSS/HTML auto). |
| **Filtrage** | Ignore les sources non Ã©ditoriales (forums, jobs, release notes, etc.). |
| **Classification** | Trie par thÃ¨me : bases de donnÃ©es, orchestration, BI, ML, Cloud... |
| **Analyse IA** | Score la pertinence de chaque article (0â€“100) via LLM. |
| **RÃ©sumÃ© IA** | GÃ©nÃ¨re un rÃ©sumÃ© hebdomadaire par thÃ¨mes avec les liens principaux. |
| **Export Markdown/JSON** | Sortie prÃªte Ã  lire ou Ã  publier (Notion, Slack, newsletterâ€¦). |

---

## ğŸ§© Structure du projet

veille-tech/
â”œâ”€â”€ main.py              # Orchestrateur global (crawl + analyse + export)
â”œâ”€â”€ veille_tech.py       # Crawler / parser RSS + HTML
â”œâ”€â”€ analyze_llm.py       # Analyse IA + rÃ©sumÃ©
â”œâ”€â”€ config.yaml          # Configuration principale
â”œâ”€â”€ veille.db            # Base SQLite (articles)
â””â”€â”€ export/
â”œâ”€â”€ digest_YYYYMMDD.md
â”œâ”€â”€ ai_selection_YYYYMMDD.md
â””â”€â”€ ai_summary_YYYYMMDD.md

---

## âš™ï¸ Installation

### 1ï¸âƒ£ CrÃ©e ton environnement

```bash
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -r requirements.txt

Exemple minimal de requirements.txt :

aiohttp
aiolimiter
feedparser
beautifulsoup4
html5lib
lxml
python-slugify
pydantic
readability-lxml
tqdm
pyyaml
openai==1.50.2
httpx==0.27.2


â¸»

2ï¸âƒ£ Configure ton config.yaml

Tous les paramÃ¨tres sont centralisÃ©s ici :
	â€¢	crawl : vitesse, timeout, filtres de domaines (whitelist/blacklist).
	â€¢	sources : flux RSS ou blogs Ã  suivre.
	â€¢	llm : paramÃ¨tres du modÃ¨le dâ€™analyse IA.
	â€¢	summary : options du rÃ©sumÃ© hebdomadaire.

Exemple :

llm:
  provider: "openai_compat"
  base_url: "https://api.groq.com/openai/v1"
  api_key_env: "GROQ_API_KEY"
  model: "llama-3.1-8b-instant"
  temperature: 0.2
  max_tokens: 400
  concurrent: 1
  score_threshold: 60


â¸»

3ï¸âƒ£ Configure ta clÃ© API Groq

CrÃ©e ton token ici â†’ https://console.groq.com/

export GROQ_API_KEY="sk_groq_xxxxxxxxxxxxxx"


â¸»

â–¶ï¸ ExÃ©cution

Tout lancer dâ€™un coup :

python main.py --config config.yaml

Options disponibles :

--skip-crawl       # saute la phase de crawling
--skip-analyze     # saute lâ€™analyse IA
--limit 10         # ne traite que 10 items (debug)

Exemples :

# Crawler uniquement
python main.py --skip-analyze

# Relancer uniquement lâ€™analyse IA
python main.py --skip-crawl


â¸»

ğŸ“Š RÃ©sultats

Les exports sont dans export/ :
	â€¢	digest_YYYYMMDD.md â†’ liste dâ€™articles par thÃ¨me
	â€¢	ai_selection_YYYYMMDD.md â†’ items filtrÃ©s par lâ€™IA (score â‰¥ threshold)
	â€¢	ai_summary_YYYYMMDD.md â†’ rÃ©sumÃ© hebdomadaire IA

Exemple de rÃ©sumÃ© :

# ğŸ§  Veille Tech â€“ Semaine du 14 octobre 2025

## ğŸ”¢ Bases de donnÃ©es
- Snowflake GA sur Dynamic Tables 2.0 â€“ gains de performance notables.
- Databricks amÃ©liore Photon SQL (+30% sur benchmarks).

**Ã€ creuser :**
- https://www.snowflake.com/blog/dynamic-tables-2-0/
- https://www.databricks.com/blog/photon-updates


â¸»

ğŸ§¹ Purge (optionnelle)

Tu peux activer la purge automatique pour ne garder que la fenÃªtre de veille (7 jours par dÃ©faut) :

with db_conn(cfg.storage.sqlite_path) as conn:
    conn.execute("DELETE FROM items WHERE published_ts < ?", (window_start_ts,))


â¸»

ğŸ› ï¸ Personnalisation
	â€¢	ğŸ§¾ Ajouter une source :
â†’ Ajoute un bloc dans config.yaml > sources
Exemple :

- name: "Datafold Blog"
  url: "https://datafold.com/blog"


	â€¢	ğŸ¯ Modifier les thÃ¨mes :
â†’ Mets Ã  jour categories (mots-clÃ©s et titres).
	â€¢	ğŸ§  Changer de modÃ¨le IA :
â†’ Utilise model: llama-3.1-70b-versatile (plus prÃ©cis mais plus lent).

â¸»

ğŸ§µ Automatisation

Tu peux planifier lâ€™exÃ©cution avec cron (Linux/macOS) :

0 9 * * 1 cd /path/to/veille-tech && /usr/bin/python3 main.py --config config.yaml >> veille.log 2>&1

â†’ Lance la veille tous les lundis Ã  9h.

â¸»

ğŸ’¡ Astuces
	â€¢	VÃ©rifie la qualitÃ© des sources :

sqlite3 veille.db "SELECT source_name, COUNT(*) FROM items GROUP BY source_name ORDER BY 2 DESC;"


	â€¢	Pour relire les articles scorÃ©s :

sqlite3 veille.db "SELECT title, llm_score, url FROM items WHERE llm_score >= 70 ORDER BY published_ts DESC;"



â¸»

ğŸ§‘â€ğŸ’» Auteur

Projet conÃ§u par Nathan Sornet
avec â¤ï¸ et Groq + Llama 3.1 pour booster la veille data/tech.

â¸»

ğŸªª Licence

MIT â€” libre dâ€™usage et de modification.
Si tu lâ€™adaptes, pense Ã  citer la source ğŸ™

---

Souhaites-tu que je te fasse aussi un **`requirements.txt` complet et figÃ©** (versions exactes testÃ©es avec ton pipeline Groq + crawler) Ã  mettre Ã  cÃ´tÃ© du README ?